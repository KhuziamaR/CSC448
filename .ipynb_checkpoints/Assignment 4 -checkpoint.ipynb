{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/KhuziamaR/CSC448/blob/master/Assignment%204%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 04\n",
    "## Khuziama Rehman\n",
    "## CSC 44800 \n",
    "## OSIS 23929365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "S8PKiVJaL_AW",
    "outputId": "23c2a4cd-0c53-4a1c-c454-7ed87e392a8c"
   },
   "outputs": [],
   "source": [
    "# Imports and pip installations (if needed)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A05Q5B0_NUX9"
   },
   "source": [
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "YZ4MUsbXNZ0P",
    "outputId": "77e7a628-792f-4d28-b7b1-e06f4db3efd3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
       "0           5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1           4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2           4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3           4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4           5.0         3.6          1.4         0.2  Iris-setosa\n",
       "5           5.4         3.9          1.7         0.4  Iris-setosa\n",
       "6           4.6         3.4          1.4         0.3  Iris-setosa\n",
       "7           5.0         3.4          1.5         0.2  Iris-setosa\n",
       "8           4.4         2.9          1.4         0.2  Iris-setosa\n",
       "9           4.9         3.1          1.5         0.1  Iris-setosa\n",
       "10          5.4         3.7          1.5         0.2  Iris-setosa\n",
       "11          4.8         3.4          1.6         0.2  Iris-setosa\n",
       "12          4.8         3.0          1.4         0.1  Iris-setosa\n",
       "13          4.3         3.0          1.1         0.1  Iris-setosa\n",
       "14          5.8         4.0          1.2         0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "# import the Iris data set\n",
    "\n",
    "iris_df = pd.read_csv(\"https://raw.githubusercontent.com/pandas-dev/pandas/main/pandas/tests/io/data/csv/iris.csv\")\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "iris_df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   SepalLength  150 non-null    float64\n",
      " 1   SepalWidth   150 non-null    float64\n",
      " 2   PetalLength  150 non-null    float64\n",
      " 3   PetalWidth   150 non-null    float64\n",
      " 4   Name         150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRMtsJKBaxWu"
   },
   "source": [
    "## About the dataset\n",
    "\n",
    "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual \n",
    "classes?\n",
    "\n",
    "Iris is a flower/plant and the Iris Dataset contains data on 3 different types of irises. The data was recorded by researchers and has 5 columns (SepalLength,SepalWidth,PetalLength,PetalWidth,Name). The data in the first 4 columns represents features of the iris plant while the 5th column represents the y-axis or target. The Iris dataset is a simple dataset that can be used by students studying machine learning to learn more about the basic Macine Learning algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhKaIrZKNaHg"
   },
   "source": [
    "# Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrgogB62NcOi",
    "outputId": "7bbfb1ea-88ed-4944-ab94-48696b9a71df"
   },
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "z = iris.target_names\n",
    "#print(X,y)\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.fit_transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hblF-ei9Ncia"
   },
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhFhEN03Nf7o",
    "outputId": "15a94661-020b-4520-b5f3-c34fdfb042f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Predictions\n",
      "2 / 15\n",
      "Percentage Accuracy:  86.66666666666667\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "lr = LogisticRegression(C=100,random_state=0, tol=0.01)\n",
    "lr.fit(X_train_std,y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "y_pred = lr.predict(X_test_std)\n",
    "print(\"Incorrect Predictions\")\n",
    "print((y_test != y_pred).sum(),\"/\",((y_test == y_pred).sum()+(y_test != y_pred).sum()))\n",
    "print(\"Percentage Accuracy: \", 100*accuracy_score(y_test,y_pred))\n",
    "# iv. Extract the coefficents and intercepts for the boundary line(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Report on the score for Logistic regression model, what does the score measure?\n",
    "\n",
    "After fitting the Logistic Regression Model with our training data, the accuracy score for the model was 86.66% and our model only made 2 wrong predictions out of the total 15 predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDUpXQN4Nilk"
   },
   "source": [
    "# Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U__zukpdNqiQ",
    "outputId": "5cd81a50-9137-4f36-842e-0687e9bc7c45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test data: [2 1 0 0 1 1 1 2 2 1 2 1 2 2 0]\n",
      "Score:  0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X,y)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(\"Predictions on test data:\",clf.predict(X_test))\n",
    "\n",
    "print(\"Score: \", clf.score(X,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report on the score for the SVM, what does the score measure?\n",
    "\n",
    "The Score for the SVM is 0.9733333333333334 which means that the model was able to classify 97% of the data correctly while 3% of the data was incorrectly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULoL7mMBNrlS"
   },
   "source": [
    "# Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKKmODVrN9lQ",
    "outputId": "dced24f7-c6bd-45fb-c68f-87548e9228dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 0s 750us/step - loss: 1.2007 - accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.9704 - accuracy: 0.3185\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.8836 - accuracy: 0.6519\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.8422 - accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7943 - accuracy: 0.6741\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.7412 - accuracy: 0.6815\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7021 - accuracy: 0.6815\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.6728 - accuracy: 0.6815\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.6497 - accuracy: 0.6815\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6815\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.5998 - accuracy: 0.7111\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.8519\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.5621 - accuracy: 0.8963\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5450 - accuracy: 0.9259\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5282 - accuracy: 0.9481\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.5135 - accuracy: 0.9333\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7778\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.4877 - accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.4850 - accuracy: 0.9407\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.4686 - accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25dfca3dfa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "#X, y = make_classification(n_samples=100, random_state=1)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
    "# Building the Model\n",
    "model= Sequential()\n",
    "model.add(Dense(100,input_shape=(4,), activation=\"relu\"))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the Model\n",
    "model.fit(X_train,y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5692 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.569157600402832, 0.800000011920929]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01190184 0.35418698 0.6339112 ]\n",
      " [0.06190368 0.4543978  0.48369855]\n",
      " [0.81338555 0.12615609 0.06045838]\n",
      " [0.8570968  0.10099722 0.04190594]\n",
      " [0.06305505 0.4764641  0.46048087]\n",
      " [0.06025628 0.43442136 0.5053224 ]\n",
      " [0.07287735 0.48816314 0.43895954]\n",
      " [0.04023521 0.42528835 0.5344764 ]\n",
      " [0.02318929 0.40437073 0.5724399 ]\n",
      " [0.16064939 0.4755519  0.3637988 ]]\n"
     ]
    }
   ],
   "source": [
    "# Predict for the first 10 Observations\n",
    "pred=model.predict(X_test[:10])\n",
    "print(pred)\n",
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bi5tDwHmC28"
   },
   "source": [
    "# Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCFlfJy2mCg6",
    "outputId": "e71bf88c-6418-4b7f-e289-4acf743c16cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "y_test.shape\n",
    "knnmodel=KNeighborsClassifier(n_neighbors=3)\n",
    "knnmodel.fit(X_train,y_train)\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',metric_params=None, n_jobs=None, n_neighbors=3, p=2, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "y_predict1=knnmodel.predict(X_test)\n",
    "acc=accuracy_score(y_test,y_predict1)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report on the score for kNN, what does the score measure?\n",
    "\n",
    "My score for kNN is 0.9333333333 which tells us that 93% of the data is correctly classified while 7% of the data was incorrectly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "162Sw3LeoqE2"
   },
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "\n",
    "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?\n",
    "\n",
    "The results of each algorithm were different. The Logistic regression accuracy was only 86% with 2/15 incorrect predictions. The SVM Support vector classifier model was the most accurate out of all the algorithms we used. This did not surprise me since the SVM model diagrams we see in the textbook accurately classify classes with multiple features. I thought that the K-nearest Neighbors Algorithm would be more accurate at classifying the data since the algorithm is used to fit data accurately based on previous data which we were given in the Iris dataset. Although The k nearest neighbos algorithm wasnt as accurate as the SVM Support Vector Classifier, it still did an amazing job at cassifying the data with 93% accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
